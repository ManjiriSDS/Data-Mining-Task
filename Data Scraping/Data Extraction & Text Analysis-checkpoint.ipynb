{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2dc338a",
   "metadata": {},
   "source": [
    "# Data Extraction & Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b34f55",
   "metadata": {},
   "source": [
    "<img src=\"images.png\" width=\"150\" height=\"150\" align=\"left\"/> \n",
    "<img src=\"data-science-isolated-icon-simple-element-illustration-general-concept-icons-editable-logo-sign-symbol-design-white-142289844.jpg\" width=\"150\" height=\"150\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35991b",
   "metadata": {},
   "source": [
    "### Submitted By Manjiri H. Sawant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22de66f",
   "metadata": {},
   "source": [
    "### Objectives : \n",
    "\n",
    "The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b108817",
   "metadata": {},
   "source": [
    "1. `Data Extraction`\n",
    "2. `Data Analysis`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47618978",
   "metadata": {},
   "source": [
    "`Tool Used`: **Python Jupyter Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27005d3",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe13517",
   "metadata": {},
   "source": [
    "1. `BeautifulSoup` - Format and Scrap the data from the HTML\n",
    "2. `Selenium` - Controlling web browser through programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe591619",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "\n",
    "1. Identify URL\n",
    "2. Inspect HTML code\n",
    "3. Find the HTML tag for the element that you want to extract.\n",
    "4. Write some code to scrap this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b5f7d",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78541c",
   "metadata": {},
   "source": [
    "`Look for these variables in the analysis:`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680265c",
   "metadata": {},
   "source": [
    "1.\tPOSITIVE SCORE\n",
    "2.\tNEGATIVE SCORE\n",
    "3.\tPOLARITY SCORE\n",
    "4.\tSUBJECTIVITY SCORE\n",
    "5.\tAVG SENTENCE LENGTH\n",
    "6.\tPERCENTAGE OF COMPLEX WORDS\n",
    "7.\tFOG INDEX\n",
    "8.\tAVG NUMBER OF WORDS PER SENTENCE\n",
    "9.\tCOMPLEX WORD COUNT\n",
    "10.\tWORD COUNT\n",
    "11.\tSYLLABLE PER WORD\n",
    "12.\tPERSONAL PRONOUNS\n",
    "13.\tAVG WORD LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bf4e2",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6e4f5",
   "metadata": {},
   "source": [
    "##### The following code written in Python 3.x. Libraries provide pre-written functionally to perform necessary tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e740dbc",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571539cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b09a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "\n",
    "df = pd.read_excel('C:/Users/User/Case Study/blackcoffer assignment/files/Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9fb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here 1st Column will be extracted ie 'URL_ID'\n",
    "# Converting specific df columns\n",
    "\n",
    "u_id = df['URL_ID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb325d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here 2nd Column will be extracted ie 'URL'\n",
    "# Converting specific df columns\n",
    "\n",
    "u_l = df['URL'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b58ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c0c7ae",
   "metadata": {},
   "source": [
    "Identify below features based on them and I will try to scrape out the relevant data from website :\n",
    "* article title ='?'\n",
    "* article text = '?'\n",
    "* Article Title = `'title'`\n",
    "* Article Text = **`div`** `'td-post-content'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd5444",
   "metadata": {},
   "source": [
    "`Tags are very important while scraping data from particular website.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41e617",
   "metadata": {},
   "source": [
    "**soup.find()** is used for finding out the first tag with the specified name or id and \n",
    "returning an object of type bs4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214446db",
   "metadata": {},
   "source": [
    "* Through WebDriver, Selenium supports all major browsers such as Chrome/Chromium, Firefox, Internet Explorer, Edge, Opera, and Safari. \n",
    "* WebDriver drives the browser using the browser’s built-in support for automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4f826",
   "metadata": {},
   "source": [
    "* **Gecko driver** links between selenium test and the Firefox browser keep **headless** to access any website easily nothing will appear on screen. \n",
    "* Everything is done on the backend side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0356d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "File written successfully\n",
      "2\n",
      "File written successfully\n",
      "3\n",
      "File written successfully\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# URL as an input \n",
    "# Iterating till the range and export as txt file\n",
    "\n",
    "\n",
    "\n",
    "time_out = time.time() + 60*1 # 1 min from now\n",
    "\n",
    "for ele in u_l:\n",
    "    try:\n",
    "        options = FirefoxOptions()\n",
    "        options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Firefox(options=options)\n",
    "        \n",
    "        \n",
    "        driver.get(ele)\n",
    "        content = driver.page_source\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            driver.close()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    soup = BeautifulSoup(content, features = \"html.parser\")\n",
    "    \n",
    "    #title\n",
    "    title = soup.find('title')\n",
    "    \n",
    "    \n",
    "    #post\n",
    "    post = soup.find('div', attrs = {'class': 'td-post-content'})\n",
    "\n",
    "    \n",
    "    data = [title.text, post.text]\n",
    "    \n",
    "    \n",
    "    x = u_id[0]\n",
    "    print(x)\n",
    "    \n",
    "\n",
    "    with open('E:/data/{}.txt'.format(x), 'w+', encoding='utf-8') as t:\n",
    "        for items in data:\n",
    "            t.write('%s\\n' %items)\n",
    "    t.close()\n",
    "    \n",
    "\n",
    "    completed.append(ele)\n",
    "    \n",
    "#     print(completed)\n",
    "    \n",
    "    print(\"File written successfully\")\n",
    "    \n",
    "    \n",
    "\n",
    "    u_id.pop(0)\n",
    "    \n",
    "    if time.time() > time_out:\n",
    "        break\n",
    "        \n",
    "for ele in completed:\n",
    "    if ele in u_l:\n",
    "        u_l.remove(ele)        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "53cc15ab",
   "metadata": {},
   "source": [
    "last = u_l[-1]\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=options)\n",
    "        \n",
    "        \n",
    "driver.get(last)\n",
    "content = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(content, features = \"html.parser\")\n",
    "post = soup.find('div', attrs = {'class': 'td-post-content'})\n",
    "\n",
    "data = [title.text, post.text]\n",
    "\n",
    "x = u_id[-1]\n",
    "\n",
    "with open('E:/data_a/{}.txt'.format(x), 'w+', encoding='utf-8') as t:\n",
    "        for items in data:\n",
    "            t.write('%s\\n' %items)\n",
    "t.close()\n",
    "    \n",
    "print(\"File written successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03395dcc",
   "metadata": {},
   "source": [
    "# 2. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e896b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc30610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in ' C:/Users/User/Case Study/blackcoffer assignment/ ' :\n"
     ]
    }
   ],
   "source": [
    "# get the list of all text files\n",
    "\n",
    "path = 'C:/Users/User/Case Study/blackcoffer assignment/'\n",
    "\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Files in '\", path, \"' :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1005217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append only text files present in my folder\n",
    "t_file = []\n",
    "\n",
    "for x in dir_list:\n",
    "    if x.endswith('.txt'):\n",
    "        t_file.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58cb1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to sort a list of strings\n",
    "# Using sort() function with key as len\n",
    "\n",
    "t_file.sort(key = len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426222a8",
   "metadata": {},
   "source": [
    "**The Master Dictionary Found Here:**\n",
    "* https://sraf.nd.edu/textual-analysis/resources/ \n",
    "* https://drive.google.com/file/d/17CmUZM9hGUdGYjCXcjQLyybjTrcjrhik/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f525e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandas Dataframe\n",
    "# change the string to lowercase in Pandas Dataframe using df['column name'].str.lower()\n",
    "# Python zip() method takes iterable or containers and \n",
    "# returns a single iterator object, having mapped values from all the containers. \n",
    "\n",
    "df = pd.read_csv('C:/Users/User/Downloads/Loughran-McDonald_MasterDictionary_1993-2021.csv')\n",
    "\n",
    "sydict = dict(zip(df.Word.str.lower(),df.Syllables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f122c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(text):\n",
    "    num_of_words = 0\n",
    "    lines = text.split()\n",
    "    for w in lines:\n",
    "        if not w.isnumeric():\n",
    "            num_of_words += 1\n",
    "    return num_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11279197",
   "metadata": {},
   "source": [
    "## Word Count "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712977ba",
   "metadata": {},
   "source": [
    "`We count the total cleaned words present in the text by:`\n",
    "1.\tremoving the stop words (using stopwords class of nltk package).\n",
    "2.\tremoving any punctuations like ? ! , . from the word before counting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71863f8c",
   "metadata": {},
   "source": [
    "**The StopWords list Found Here:**\n",
    "* https://sraf.nd.edu/textual-analysis/stopwords/\n",
    "* https://drive.google.com/file/d/0B4niqV00F3msSktONVhfaElXeEk/view?resourcekey=0-3hFK5VYPXA7R_Q2LvA-SOw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a313355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('C:/Users/User/Case Study/blackcoffer assignment/files/StopWords_GenericLong.txt').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32687075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple python function 1\n",
    "# total cleaned word present in the text\n",
    "\n",
    "\n",
    "def clean_word(text):\n",
    "    filtered = []\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    clean = tokenizer.tokenize(text)\n",
    "    \n",
    "    for w in clean:\n",
    "        if w not in stopwords:\n",
    "            if w.isalpha():\n",
    "                filtered.append(w)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96b9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple python function 2\n",
    "# count total cleaned word present in the text\n",
    "\n",
    "\n",
    "def word_count(text):\n",
    "    filtered = []\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    clean = tokenizer.tokenize(text)\n",
    "    \n",
    "    for w in clean:\n",
    "        if w not in stopwords:\n",
    "            if w.isalpha():\n",
    "                filtered.append(w)\n",
    "    return len(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38a25f",
   "metadata": {},
   "source": [
    "## Positive Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e033e",
   "metadata": {},
   "source": [
    "**This file contains a list of POSITIVE opinion words (or sentiment words).**\n",
    "\n",
    "* This file and the papers can all be downloaded from \n",
    "http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "If you use this list, please cite one of the following two papers:\n",
    "   *  Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" Proceedings of the ACM SIGKDD International\n",
    "       Conference on Knowledge Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, Washington, USA, \n",
    "   *   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing and Comparing Opinions on the Web.\" Proceedings of        the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d950c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positve words\n",
    "# opening the file in read mode\n",
    "file1 = open('E:/Blackcoffer case study/positive-words.txt','r')\n",
    "\n",
    "# reading the file\n",
    "data1 = file1.read()\n",
    "\n",
    "# splitting the text \n",
    "p_word = data1.split()\n",
    "# print(p_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c73fd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_score(text):\n",
    "    values = []\n",
    "    for item in text:\n",
    "        if item in p_word:\n",
    "            score = +1\n",
    "            values.append(score)\n",
    "    return sum(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32496d00",
   "metadata": {},
   "source": [
    "## Negative Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c31c9e",
   "metadata": {},
   "source": [
    "**Dictionary of Negative Words Found Here :**\n",
    "\n",
    "* This file contains a list of NEGATIVE opinion words (or sentiment words).\n",
    "\n",
    "* This file and the papers can all be downloaded from:\n",
    "    \n",
    "  http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "If you use this list, please cite one of the following two papers:\n",
    "   *  Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" Proceedings of the ACM SIGKDD International\n",
    "       Conference on Knowledge Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, Washington, USA, \n",
    "   *   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing and Comparing Opinions on the Web.\" Proceedings of        the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan.\n",
    "\n",
    "https://gist.github.com/mkulakowski2/4289441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3e09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative words\n",
    "\n",
    "#opening the file in read mode\n",
    "file2 = open('E:/Blackcoffer case study/negative-words.txt','r')\n",
    "\n",
    "#reading the file\n",
    "data2 = file2.read()\n",
    "\n",
    "#spliting the text\n",
    "n_word = data2.split()\n",
    "# print(n_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "258144b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score(text):\n",
    "    values = []\n",
    "    for item in text:\n",
    "        if item in n_word:\n",
    "            score = -1\n",
    "            values.append(score)\n",
    "    final = sum(values) * -1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb9d14",
   "metadata": {},
   "source": [
    "## Polarity Score\n",
    "\n",
    "This is the score that determines if a given text is positive or negative in nature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0776bb3",
   "metadata": {},
   "source": [
    "It is calculated by using the formula: \n",
    "**Polarity Score** = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "\n",
    "`Range is from -1 to +1`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28895091",
   "metadata": {},
   "source": [
    "## Subjectivity Score\n",
    "\n",
    "This is the score that determines if a given text is objective or subjective. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70305ca",
   "metadata": {},
   "source": [
    "It is calculated by using the formula: \n",
    "\n",
    "**Subjectivity Score** = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "\n",
    "`Range is from 0 to +1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d040d004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "Successful\n",
      "2.txt\n",
      "Successful\n",
      "3.txt\n",
      "Successful\n",
      "4.txt\n",
      "Successful\n",
      "5.txt\n",
      "Successful\n",
      "6.txt\n",
      "Successful\n",
      "7.txt\n",
      "Successful\n",
      "8.txt\n",
      "Successful\n",
      "9.txt\n",
      "Successful\n",
      "10.txt\n",
      "Successful\n",
      "11.txt\n",
      "Successful\n",
      "12.txt\n",
      "Successful\n",
      "13.txt\n",
      "Successful\n",
      "14.txt\n",
      "Successful\n",
      "15.txt\n",
      "Successful\n",
      "16.txt\n",
      "Successful\n",
      "17.txt\n",
      "Successful\n",
      "18.txt\n",
      "Successful\n",
      "19.txt\n",
      "Successful\n",
      "20.txt\n",
      "Successful\n",
      "21.txt\n",
      "Successful\n",
      "22.txt\n",
      "Successful\n",
      "23.txt\n",
      "Successful\n",
      "24.txt\n",
      "Successful\n",
      "25.txt\n",
      "Successful\n",
      "26.txt\n",
      "Successful\n",
      "27.txt\n",
      "Successful\n",
      "28.txt\n",
      "Successful\n",
      "29.txt\n",
      "Successful\n",
      "30.txt\n",
      "Successful\n",
      "31.txt\n",
      "Successful\n",
      "32.txt\n",
      "Successful\n",
      "33.txt\n",
      "Successful\n",
      "34.txt\n",
      "Successful\n",
      "35.txt\n",
      "Successful\n",
      "36.txt\n",
      "Successful\n",
      "37.txt\n",
      "Successful\n",
      "38.txt\n",
      "Successful\n",
      "39.txt\n",
      "Successful\n",
      "40.txt\n",
      "Successful\n",
      "41.txt\n",
      "Successful\n",
      "42.txt\n",
      "Successful\n",
      "43.txt\n",
      "Successful\n",
      "45.txt\n",
      "Successful\n",
      "46.txt\n",
      "Successful\n",
      "47.txt\n",
      "Successful\n",
      "48.txt\n",
      "Successful\n",
      "49.txt\n",
      "Successful\n",
      "50.txt\n",
      "Successful\n",
      "51.txt\n",
      "Successful\n",
      "52.txt\n",
      "Successful\n",
      "53.txt\n",
      "Successful\n",
      "54.txt\n",
      "Successful\n",
      "55.txt\n",
      "Successful\n",
      "56.txt\n",
      "Successful\n",
      "57.txt\n",
      "Successful\n",
      "58.txt\n",
      "Successful\n",
      "59.txt\n",
      "Successful\n",
      "60.txt\n",
      "Successful\n",
      "61.txt\n",
      "Successful\n",
      "62.txt\n",
      "Successful\n",
      "63.txt\n",
      "Successful\n",
      "64.txt\n",
      "Successful\n",
      "65.txt\n",
      "Successful\n",
      "66.txt\n",
      "Successful\n",
      "67.txt\n",
      "Successful\n",
      "68.txt\n",
      "Successful\n",
      "69.txt\n",
      "Successful\n",
      "70.txt\n",
      "Successful\n",
      "71.txt\n",
      "Successful\n",
      "72.txt\n",
      "Successful\n",
      "73.txt\n",
      "Successful\n",
      "74.txt\n",
      "Successful\n",
      "75.txt\n",
      "Successful\n",
      "76.txt\n",
      "Successful\n",
      "77.txt\n",
      "Successful\n",
      "78.txt\n",
      "Successful\n",
      "79.txt\n",
      "Successful\n",
      "80.txt\n",
      "Successful\n",
      "81.txt\n",
      "Successful\n",
      "82.txt\n",
      "Successful\n",
      "83.txt\n",
      "Successful\n",
      "84.txt\n",
      "Successful\n",
      "85.txt\n",
      "Successful\n",
      "86.txt\n",
      "Successful\n",
      "87.txt\n",
      "Successful\n",
      "88.txt\n",
      "Successful\n",
      "89.txt\n",
      "Successful\n",
      "90.txt\n",
      "Successful\n",
      "91.txt\n",
      "Successful\n",
      "92.txt\n",
      "Successful\n",
      "93.txt\n",
      "Successful\n",
      "94.txt\n",
      "Successful\n",
      "95.txt\n",
      "Successful\n",
      "96.txt\n",
      "Successful\n",
      "97.txt\n",
      "Successful\n",
      "98.txt\n",
      "Successful\n",
      "99.txt\n",
      "Successful\n",
      "100.txt\n",
      "Successful\n",
      "101.txt\n",
      "Successful\n",
      "102.txt\n",
      "Successful\n",
      "103.txt\n",
      "Successful\n",
      "104.txt\n",
      "Successful\n",
      "105.txt\n",
      "Successful\n",
      "106.txt\n",
      "Successful\n",
      "107.txt\n",
      "Successful\n",
      "108.txt\n",
      "Successful\n",
      "109.txt\n",
      "Successful\n",
      "110.txt\n",
      "Successful\n",
      "111.txt\n",
      "Successful\n",
      "112.txt\n",
      "Successful\n",
      "113.txt\n",
      "Successful\n",
      "114.txt\n",
      "Successful\n",
      "115.txt\n",
      "Successful\n",
      "116.txt\n",
      "Successful\n",
      "117.txt\n",
      "Successful\n",
      "118.txt\n",
      "Successful\n",
      "119.txt\n",
      "Successful\n",
      "120.txt\n",
      "Successful\n",
      "121.txt\n",
      "Successful\n",
      "122.txt\n",
      "Successful\n",
      "123.txt\n",
      "Successful\n",
      "124.txt\n",
      "Successful\n",
      "125.txt\n",
      "Successful\n",
      "126.txt\n",
      "Successful\n",
      "127.txt\n",
      "Successful\n",
      "128.txt\n",
      "Successful\n",
      "129.txt\n",
      "Successful\n",
      "130.txt\n",
      "Successful\n",
      "131.txt\n",
      "Successful\n",
      "132.txt\n",
      "Successful\n",
      "133.txt\n",
      "Successful\n",
      "134.txt\n",
      "Successful\n",
      "135.txt\n",
      "Successful\n",
      "136.txt\n",
      "Successful\n",
      "137.txt\n",
      "Successful\n",
      "138.txt\n",
      "Successful\n",
      "139.txt\n",
      "Successful\n",
      "140.txt\n",
      "Successful\n",
      "141.txt\n",
      "Successful\n",
      "142.txt\n",
      "Successful\n",
      "143.txt\n",
      "Successful\n",
      "144.txt\n",
      "Successful\n",
      "145.txt\n",
      "Successful\n",
      "146.txt\n",
      "Successful\n",
      "147.txt\n",
      "Successful\n",
      "148.txt\n",
      "Successful\n",
      "149.txt\n",
      "Successful\n",
      "150.txt\n",
      "Successful\n",
      "151.txt\n",
      "Successful\n",
      "152.txt\n",
      "Successful\n",
      "153.txt\n",
      "Successful\n",
      "154.txt\n",
      "Successful\n",
      "155.txt\n",
      "Successful\n",
      "156.txt\n",
      "Successful\n",
      "157.txt\n",
      "Successful\n",
      "158.txt\n",
      "Successful\n",
      "159.txt\n",
      "Successful\n",
      "160.txt\n",
      "Successful\n",
      "161.txt\n",
      "Successful\n",
      "162.txt\n",
      "Successful\n",
      "163.txt\n",
      "Successful\n",
      "164.txt\n",
      "Successful\n",
      "165.txt\n",
      "Successful\n",
      "166.txt\n",
      "Successful\n",
      "167.txt\n",
      "Successful\n",
      "168.txt\n",
      "Successful\n",
      "169.txt\n",
      "Successful\n",
      "170.txt\n",
      "Successful\n",
      "171.txt\n",
      "Successful\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cl_w = []         # total number of clean words\n",
    "score_1 = []      # Positive Score\n",
    "score_2 = []      # Negative Score\n",
    "score_3 = []      # Polarity Score\n",
    "score_4 = []      # Subjectivity Score\n",
    "\n",
    "\n",
    "for x in t_file:\n",
    "    article = open(x, encoding = 'mbcs').read().lower()\n",
    "    \n",
    "    # Clean Words\n",
    "    f = clean_word(article)\n",
    "   \n",
    "    \n",
    "    # Clean Word Count\n",
    "    m = word_count(article)\n",
    "    cl_w.append(m)\n",
    "   \n",
    "    \n",
    "    # Positive Score\n",
    "    ps = positive_score(f)\n",
    "    score_1.append(ps)\n",
    "   \n",
    "   \n",
    "    # Negative Score\n",
    "    ns = negative_score(f)\n",
    "    score_2.append(ns)\n",
    "   \n",
    "   \n",
    "    # Polarity Score\n",
    "    w = round(((ps-ns)/((ps+ns) + 0.000001)),2)\n",
    "    score_3.append(w)\n",
    "    \n",
    "    # Subjectivity Score\n",
    "    v = round(((ps + ns)/(m + 0.000001)),2)\n",
    "    score_4.append(v)\n",
    "    \n",
    "    \n",
    "    print(x)\n",
    "    print('Successful')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8ba0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cl_w)\n",
    "# print(score_1)\n",
    "# print(score_2)\n",
    "# print(score_3)\n",
    "# print(score_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6ff92",
   "metadata": {},
   "source": [
    "## Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86546b6e",
   "metadata": {},
   "source": [
    "`The formula for calculating is:`\n",
    "\n",
    "**Average Number of Words Per Sentence** = the total number of words / the total number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ec8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple python function\n",
    "# calculate average sentence length\n",
    "\n",
    "def avg_sent_len(text):\n",
    "    s = sent_tokenize(text)\n",
    "    ns = len(s)\n",
    "    asl = round((k/ns),2)\n",
    "    return asl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d28845",
   "metadata": {},
   "source": [
    "## Complex Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd5952",
   "metadata": {},
   "source": [
    "`Complex words are words in the text that contain more than two syllables.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d940dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple python function 4\n",
    "# count complex word which has more than two syllables\n",
    "\n",
    "def complex_word_count(t_dict,t_lst):\n",
    "    complx = []\n",
    "    for w in t_lst:\n",
    "        for key,val in t_dict.items():\n",
    "            if w == key:\n",
    "                if val > 2:\n",
    "                    complx.append(w)\n",
    "    return(len(complx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d0650",
   "metadata": {},
   "source": [
    "## Analysis of Readability\n",
    "\n",
    "Analysis of Readability is calculated using the Gunning Fox index formula described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29bd93",
   "metadata": {},
   "source": [
    "* **Average Sentence Length** = the number of words / the number of sentences\n",
    "* **Percentage of Complex words** = the number of complex words / the number of words \n",
    "* **Fog Index** = 0.4 * (Average Sentence Length + Percentage of Complex words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387583d",
   "metadata": {},
   "source": [
    "* **The Gunning Fog** formula generates a grade level between `0 and 20.` \n",
    "* It estimates the education level required to understand the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99ef9d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "Successful\n",
      "2.txt\n",
      "Successful\n",
      "3.txt\n",
      "Successful\n",
      "4.txt\n",
      "Successful\n",
      "5.txt\n",
      "Successful\n",
      "6.txt\n",
      "Successful\n",
      "7.txt\n",
      "Successful\n",
      "8.txt\n",
      "Successful\n",
      "9.txt\n",
      "Successful\n",
      "10.txt\n",
      "Successful\n",
      "11.txt\n",
      "Successful\n",
      "12.txt\n",
      "Successful\n",
      "13.txt\n",
      "Successful\n",
      "14.txt\n",
      "Successful\n",
      "15.txt\n",
      "Successful\n",
      "16.txt\n",
      "Successful\n",
      "17.txt\n",
      "Successful\n",
      "18.txt\n",
      "Successful\n",
      "19.txt\n",
      "Successful\n",
      "20.txt\n",
      "Successful\n",
      "21.txt\n",
      "Successful\n",
      "22.txt\n",
      "Successful\n",
      "23.txt\n",
      "Successful\n",
      "24.txt\n",
      "Successful\n",
      "25.txt\n",
      "Successful\n",
      "26.txt\n",
      "Successful\n",
      "27.txt\n",
      "Successful\n",
      "28.txt\n",
      "Successful\n",
      "29.txt\n",
      "Successful\n",
      "30.txt\n",
      "Successful\n",
      "31.txt\n",
      "Successful\n",
      "32.txt\n",
      "Successful\n",
      "33.txt\n",
      "Successful\n",
      "34.txt\n",
      "Successful\n",
      "35.txt\n",
      "Successful\n",
      "36.txt\n",
      "Successful\n",
      "37.txt\n",
      "Successful\n",
      "38.txt\n",
      "Successful\n",
      "39.txt\n",
      "Successful\n",
      "40.txt\n",
      "Successful\n",
      "41.txt\n",
      "Successful\n",
      "42.txt\n",
      "Successful\n",
      "43.txt\n",
      "Successful\n",
      "45.txt\n",
      "Successful\n",
      "46.txt\n",
      "Successful\n",
      "47.txt\n",
      "Successful\n",
      "48.txt\n",
      "Successful\n",
      "49.txt\n",
      "Successful\n",
      "50.txt\n",
      "Successful\n",
      "51.txt\n",
      "Successful\n",
      "52.txt\n",
      "Successful\n",
      "53.txt\n",
      "Successful\n",
      "54.txt\n",
      "Successful\n",
      "55.txt\n",
      "Successful\n",
      "56.txt\n",
      "Successful\n",
      "57.txt\n",
      "Successful\n",
      "58.txt\n",
      "Successful\n",
      "59.txt\n",
      "Successful\n",
      "60.txt\n",
      "Successful\n",
      "61.txt\n",
      "Successful\n",
      "62.txt\n",
      "Successful\n",
      "63.txt\n",
      "Successful\n",
      "64.txt\n",
      "Successful\n",
      "65.txt\n",
      "Successful\n",
      "66.txt\n",
      "Successful\n",
      "67.txt\n",
      "Successful\n",
      "68.txt\n",
      "Successful\n",
      "69.txt\n",
      "Successful\n",
      "70.txt\n",
      "Successful\n",
      "71.txt\n",
      "Successful\n",
      "72.txt\n",
      "Successful\n",
      "73.txt\n",
      "Successful\n",
      "74.txt\n",
      "Successful\n",
      "75.txt\n",
      "Successful\n",
      "76.txt\n",
      "Successful\n",
      "77.txt\n",
      "Successful\n",
      "78.txt\n",
      "Successful\n",
      "79.txt\n",
      "Successful\n",
      "80.txt\n",
      "Successful\n",
      "81.txt\n",
      "Successful\n",
      "82.txt\n",
      "Successful\n",
      "83.txt\n",
      "Successful\n",
      "84.txt\n",
      "Successful\n",
      "85.txt\n",
      "Successful\n",
      "86.txt\n",
      "Successful\n",
      "87.txt\n",
      "Successful\n",
      "88.txt\n",
      "Successful\n",
      "89.txt\n",
      "Successful\n",
      "90.txt\n",
      "Successful\n",
      "91.txt\n",
      "Successful\n",
      "92.txt\n",
      "Successful\n",
      "93.txt\n",
      "Successful\n",
      "94.txt\n",
      "Successful\n",
      "95.txt\n",
      "Successful\n",
      "96.txt\n",
      "Successful\n",
      "97.txt\n",
      "Successful\n",
      "98.txt\n",
      "Successful\n",
      "99.txt\n",
      "Successful\n",
      "100.txt\n",
      "Successful\n",
      "101.txt\n",
      "Successful\n",
      "102.txt\n",
      "Successful\n",
      "103.txt\n",
      "Successful\n",
      "104.txt\n",
      "Successful\n",
      "105.txt\n",
      "Successful\n",
      "106.txt\n",
      "Successful\n",
      "107.txt\n",
      "Successful\n",
      "108.txt\n",
      "Successful\n",
      "109.txt\n",
      "Successful\n",
      "110.txt\n",
      "Successful\n",
      "111.txt\n",
      "Successful\n",
      "112.txt\n",
      "Successful\n",
      "113.txt\n",
      "Successful\n",
      "114.txt\n",
      "Successful\n",
      "115.txt\n",
      "Successful\n",
      "116.txt\n",
      "Successful\n",
      "117.txt\n",
      "Successful\n",
      "118.txt\n",
      "Successful\n",
      "119.txt\n",
      "Successful\n",
      "120.txt\n",
      "Successful\n",
      "121.txt\n",
      "Successful\n",
      "122.txt\n",
      "Successful\n",
      "123.txt\n",
      "Successful\n",
      "124.txt\n",
      "Successful\n",
      "125.txt\n",
      "Successful\n",
      "126.txt\n",
      "Successful\n",
      "127.txt\n",
      "Successful\n",
      "128.txt\n",
      "Successful\n",
      "129.txt\n",
      "Successful\n",
      "130.txt\n",
      "Successful\n",
      "131.txt\n",
      "Successful\n",
      "132.txt\n",
      "Successful\n",
      "133.txt\n",
      "Successful\n",
      "134.txt\n",
      "Successful\n",
      "135.txt\n",
      "Successful\n",
      "136.txt\n",
      "Successful\n",
      "137.txt\n",
      "Successful\n",
      "138.txt\n",
      "Successful\n",
      "139.txt\n",
      "Successful\n",
      "140.txt\n",
      "Successful\n",
      "141.txt\n",
      "Successful\n",
      "142.txt\n",
      "Successful\n",
      "143.txt\n",
      "Successful\n",
      "144.txt\n",
      "Successful\n",
      "145.txt\n",
      "Successful\n",
      "146.txt\n",
      "Successful\n",
      "147.txt\n",
      "Successful\n",
      "148.txt\n",
      "Successful\n",
      "149.txt\n",
      "Successful\n",
      "150.txt\n",
      "Successful\n",
      "151.txt\n",
      "Successful\n",
      "152.txt\n",
      "Successful\n",
      "153.txt\n",
      "Successful\n",
      "154.txt\n",
      "Successful\n",
      "155.txt\n",
      "Successful\n",
      "156.txt\n",
      "Successful\n",
      "157.txt\n",
      "Successful\n",
      "158.txt\n",
      "Successful\n",
      "159.txt\n",
      "Successful\n",
      "160.txt\n",
      "Successful\n",
      "161.txt\n",
      "Successful\n",
      "162.txt\n",
      "Successful\n",
      "163.txt\n",
      "Successful\n",
      "164.txt\n",
      "Successful\n",
      "165.txt\n",
      "Successful\n",
      "166.txt\n",
      "Successful\n",
      "167.txt\n",
      "Successful\n",
      "168.txt\n",
      "Successful\n",
      "169.txt\n",
      "Successful\n",
      "170.txt\n",
      "Successful\n",
      "171.txt\n",
      "Successful\n",
      "Wall time: 32min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num = []    # Total Number of Words\n",
    "hard = []   # Complex Word Count\n",
    "sent = []   # Average Sentence Length\n",
    "percent = []  # Percentage of Complex Words\n",
    "fog_index = [] # Fog Index\n",
    "\n",
    "\n",
    "for x in t_file:\n",
    "    article = open(x, encoding = 'mbcs').read().lower()\n",
    "    \n",
    "    # Clean Words\n",
    "    f = clean_word(article)\n",
    "    \n",
    "    # Number of Words\n",
    "    k = count(article)\n",
    "    num.append(k)\n",
    "    \n",
    "    # Complex Word Count\n",
    "    cw = complex_word_count(sydict,f)\n",
    "    hard.append(cw)\n",
    "    \n",
    "    # Average Sentence Length\n",
    "    al = avg_sent_len(article)\n",
    "    sent.append(al)\n",
    "    \n",
    "    # Percentage of Complex Words\n",
    "    pcw = round((cw/k),2)\n",
    "    percent.append(pcw)\n",
    "    \n",
    "    # Fog Index\n",
    "    fi = round((0.4* (al+pcw)),2)\n",
    "    fog_index.append(fi)\n",
    "    \n",
    "    \n",
    "    print(x)\n",
    "    print('Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b72c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hard)\n",
    "# print(sent)\n",
    "# print(fog_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a8c18",
   "metadata": {},
   "source": [
    "## Average Word Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8527b6",
   "metadata": {},
   "source": [
    "Average Word Length is calculated by the formula:\n",
    "\n",
    "`Sum of the total number of characters in each word/Total number of words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db15e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regular Expression\n",
    "\n",
    "def avg_word_length(text):\n",
    "    tk1 = RegexpTokenizer(\"[\\w']+\") # tokenize word\n",
    "    tk2 = RegexpTokenizer(\"[\\w']\")  # tokenize char in each word\n",
    "    \n",
    "    x = tk1.tokenize(text)\n",
    "    z = []\n",
    "    \n",
    "    for item in x:\n",
    "        y = tk2.tokenize(item)\n",
    "        total = len(y)\n",
    "        z.append(total)\n",
    "    \n",
    "    awl = round((sum(z)/k),0)\n",
    "    \n",
    "    return int(awl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9506bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "Successful\n",
      "2.txt\n",
      "Successful\n",
      "3.txt\n",
      "Successful\n",
      "4.txt\n",
      "Successful\n",
      "5.txt\n",
      "Successful\n",
      "6.txt\n",
      "Successful\n",
      "7.txt\n",
      "Successful\n",
      "8.txt\n",
      "Successful\n",
      "9.txt\n",
      "Successful\n",
      "10.txt\n",
      "Successful\n",
      "11.txt\n",
      "Successful\n",
      "12.txt\n",
      "Successful\n",
      "13.txt\n",
      "Successful\n",
      "14.txt\n",
      "Successful\n",
      "15.txt\n",
      "Successful\n",
      "16.txt\n",
      "Successful\n",
      "17.txt\n",
      "Successful\n",
      "18.txt\n",
      "Successful\n",
      "19.txt\n",
      "Successful\n",
      "20.txt\n",
      "Successful\n",
      "21.txt\n",
      "Successful\n",
      "22.txt\n",
      "Successful\n",
      "23.txt\n",
      "Successful\n",
      "24.txt\n",
      "Successful\n",
      "25.txt\n",
      "Successful\n",
      "26.txt\n",
      "Successful\n",
      "27.txt\n",
      "Successful\n",
      "28.txt\n",
      "Successful\n",
      "29.txt\n",
      "Successful\n",
      "30.txt\n",
      "Successful\n",
      "31.txt\n",
      "Successful\n",
      "32.txt\n",
      "Successful\n",
      "33.txt\n",
      "Successful\n",
      "34.txt\n",
      "Successful\n",
      "35.txt\n",
      "Successful\n",
      "36.txt\n",
      "Successful\n",
      "37.txt\n",
      "Successful\n",
      "38.txt\n",
      "Successful\n",
      "39.txt\n",
      "Successful\n",
      "40.txt\n",
      "Successful\n",
      "41.txt\n",
      "Successful\n",
      "42.txt\n",
      "Successful\n",
      "43.txt\n",
      "Successful\n",
      "45.txt\n",
      "Successful\n",
      "46.txt\n",
      "Successful\n",
      "47.txt\n",
      "Successful\n",
      "48.txt\n",
      "Successful\n",
      "49.txt\n",
      "Successful\n",
      "50.txt\n",
      "Successful\n",
      "51.txt\n",
      "Successful\n",
      "52.txt\n",
      "Successful\n",
      "53.txt\n",
      "Successful\n",
      "54.txt\n",
      "Successful\n",
      "55.txt\n",
      "Successful\n",
      "56.txt\n",
      "Successful\n",
      "57.txt\n",
      "Successful\n",
      "58.txt\n",
      "Successful\n",
      "59.txt\n",
      "Successful\n",
      "60.txt\n",
      "Successful\n",
      "61.txt\n",
      "Successful\n",
      "62.txt\n",
      "Successful\n",
      "63.txt\n",
      "Successful\n",
      "64.txt\n",
      "Successful\n",
      "65.txt\n",
      "Successful\n",
      "66.txt\n",
      "Successful\n",
      "67.txt\n",
      "Successful\n",
      "68.txt\n",
      "Successful\n",
      "69.txt\n",
      "Successful\n",
      "70.txt\n",
      "Successful\n",
      "71.txt\n",
      "Successful\n",
      "72.txt\n",
      "Successful\n",
      "73.txt\n",
      "Successful\n",
      "74.txt\n",
      "Successful\n",
      "75.txt\n",
      "Successful\n",
      "76.txt\n",
      "Successful\n",
      "77.txt\n",
      "Successful\n",
      "78.txt\n",
      "Successful\n",
      "79.txt\n",
      "Successful\n",
      "80.txt\n",
      "Successful\n",
      "81.txt\n",
      "Successful\n",
      "82.txt\n",
      "Successful\n",
      "83.txt\n",
      "Successful\n",
      "84.txt\n",
      "Successful\n",
      "85.txt\n",
      "Successful\n",
      "86.txt\n",
      "Successful\n",
      "87.txt\n",
      "Successful\n",
      "88.txt\n",
      "Successful\n",
      "89.txt\n",
      "Successful\n",
      "90.txt\n",
      "Successful\n",
      "91.txt\n",
      "Successful\n",
      "92.txt\n",
      "Successful\n",
      "93.txt\n",
      "Successful\n",
      "94.txt\n",
      "Successful\n",
      "95.txt\n",
      "Successful\n",
      "96.txt\n",
      "Successful\n",
      "97.txt\n",
      "Successful\n",
      "98.txt\n",
      "Successful\n",
      "99.txt\n",
      "Successful\n",
      "100.txt\n",
      "Successful\n",
      "101.txt\n",
      "Successful\n",
      "102.txt\n",
      "Successful\n",
      "103.txt\n",
      "Successful\n",
      "104.txt\n",
      "Successful\n",
      "105.txt\n",
      "Successful\n",
      "106.txt\n",
      "Successful\n",
      "107.txt\n",
      "Successful\n",
      "108.txt\n",
      "Successful\n",
      "109.txt\n",
      "Successful\n",
      "110.txt\n",
      "Successful\n",
      "111.txt\n",
      "Successful\n",
      "112.txt\n",
      "Successful\n",
      "113.txt\n",
      "Successful\n",
      "114.txt\n",
      "Successful\n",
      "115.txt\n",
      "Successful\n",
      "116.txt\n",
      "Successful\n",
      "117.txt\n",
      "Successful\n",
      "118.txt\n",
      "Successful\n",
      "119.txt\n",
      "Successful\n",
      "120.txt\n",
      "Successful\n",
      "121.txt\n",
      "Successful\n",
      "122.txt\n",
      "Successful\n",
      "123.txt\n",
      "Successful\n",
      "124.txt\n",
      "Successful\n",
      "125.txt\n",
      "Successful\n",
      "126.txt\n",
      "Successful\n",
      "127.txt\n",
      "Successful\n",
      "128.txt\n",
      "Successful\n",
      "129.txt\n",
      "Successful\n",
      "130.txt\n",
      "Successful\n",
      "131.txt\n",
      "Successful\n",
      "132.txt\n",
      "Successful\n",
      "133.txt\n",
      "Successful\n",
      "134.txt\n",
      "Successful\n",
      "135.txt\n",
      "Successful\n",
      "136.txt\n",
      "Successful\n",
      "137.txt\n",
      "Successful\n",
      "138.txt\n",
      "Successful\n",
      "139.txt\n",
      "Successful\n",
      "140.txt\n",
      "Successful\n",
      "141.txt\n",
      "Successful\n",
      "142.txt\n",
      "Successful\n",
      "143.txt\n",
      "Successful\n",
      "144.txt\n",
      "Successful\n",
      "145.txt\n",
      "Successful\n",
      "146.txt\n",
      "Successful\n",
      "147.txt\n",
      "Successful\n",
      "148.txt\n",
      "Successful\n",
      "149.txt\n",
      "Successful\n",
      "150.txt\n",
      "Successful\n",
      "151.txt\n",
      "Successful\n",
      "152.txt\n",
      "Successful\n",
      "153.txt\n",
      "Successful\n",
      "154.txt\n",
      "Successful\n",
      "155.txt\n",
      "Successful\n",
      "156.txt\n",
      "Successful\n",
      "157.txt\n",
      "Successful\n",
      "158.txt\n",
      "Successful\n",
      "159.txt\n",
      "Successful\n",
      "160.txt\n",
      "Successful\n",
      "161.txt\n",
      "Successful\n",
      "162.txt\n",
      "Successful\n",
      "163.txt\n",
      "Successful\n",
      "164.txt\n",
      "Successful\n",
      "165.txt\n",
      "Successful\n",
      "166.txt\n",
      "Successful\n",
      "167.txt\n",
      "Successful\n",
      "168.txt\n",
      "Successful\n",
      "169.txt\n",
      "Successful\n",
      "170.txt\n",
      "Successful\n",
      "171.txt\n",
      "Successful\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "awl = []\n",
    "\n",
    "\n",
    "for x in t_file:\n",
    "    article = open(x, encoding = 'mbcs').read().lower()\n",
    "    \n",
    "        \n",
    "    # Number of Words\n",
    "    k = count(article)\n",
    "    \n",
    "    \n",
    "    # Average Word Length\n",
    "    a = avg_word_length(article)\n",
    "    awl.append(a)\n",
    "    \n",
    "    \n",
    "    print(x)\n",
    "    print('Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa734994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(awl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabed4b8",
   "metadata": {},
   "source": [
    "## Personal Pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a300b",
   "metadata": {},
   "source": [
    "To calculate Personal Pronouns mentioned in the text, we use regex to find the counts of the words - “I,” “we,” “my,” “ours,” and “us”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c8eeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronouns_count(text):\n",
    "    pk = RegexpTokenizer(\"((?:^I[\\s]|your|you|^he|^she|[\\s]its|[\\s]it[\\s]|^we|they|[\\s]them[\\s]|[\\s]+us+[\\s]|[\\s]him|[\\s]her|[\\s]his|theirs|[\\s]our|[\\s]my[\\s]))\")\n",
    "    \n",
    "    pp = pk.tokenize(text)\n",
    "    \n",
    "    return len(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4137f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "Successful\n",
      "2.txt\n",
      "Successful\n",
      "3.txt\n",
      "Successful\n",
      "4.txt\n",
      "Successful\n",
      "5.txt\n",
      "Successful\n",
      "6.txt\n",
      "Successful\n",
      "7.txt\n",
      "Successful\n",
      "8.txt\n",
      "Successful\n",
      "9.txt\n",
      "Successful\n",
      "10.txt\n",
      "Successful\n",
      "11.txt\n",
      "Successful\n",
      "12.txt\n",
      "Successful\n",
      "13.txt\n",
      "Successful\n",
      "14.txt\n",
      "Successful\n",
      "15.txt\n",
      "Successful\n",
      "16.txt\n",
      "Successful\n",
      "17.txt\n",
      "Successful\n",
      "18.txt\n",
      "Successful\n",
      "19.txt\n",
      "Successful\n",
      "20.txt\n",
      "Successful\n",
      "21.txt\n",
      "Successful\n",
      "22.txt\n",
      "Successful\n",
      "23.txt\n",
      "Successful\n",
      "24.txt\n",
      "Successful\n",
      "25.txt\n",
      "Successful\n",
      "26.txt\n",
      "Successful\n",
      "27.txt\n",
      "Successful\n",
      "28.txt\n",
      "Successful\n",
      "29.txt\n",
      "Successful\n",
      "30.txt\n",
      "Successful\n",
      "31.txt\n",
      "Successful\n",
      "32.txt\n",
      "Successful\n",
      "33.txt\n",
      "Successful\n",
      "34.txt\n",
      "Successful\n",
      "35.txt\n",
      "Successful\n",
      "36.txt\n",
      "Successful\n",
      "37.txt\n",
      "Successful\n",
      "38.txt\n",
      "Successful\n",
      "39.txt\n",
      "Successful\n",
      "40.txt\n",
      "Successful\n",
      "41.txt\n",
      "Successful\n",
      "42.txt\n",
      "Successful\n",
      "43.txt\n",
      "Successful\n",
      "45.txt\n",
      "Successful\n",
      "46.txt\n",
      "Successful\n",
      "47.txt\n",
      "Successful\n",
      "48.txt\n",
      "Successful\n",
      "49.txt\n",
      "Successful\n",
      "50.txt\n",
      "Successful\n",
      "51.txt\n",
      "Successful\n",
      "52.txt\n",
      "Successful\n",
      "53.txt\n",
      "Successful\n",
      "54.txt\n",
      "Successful\n",
      "55.txt\n",
      "Successful\n",
      "56.txt\n",
      "Successful\n",
      "57.txt\n",
      "Successful\n",
      "58.txt\n",
      "Successful\n",
      "59.txt\n",
      "Successful\n",
      "60.txt\n",
      "Successful\n",
      "61.txt\n",
      "Successful\n",
      "62.txt\n",
      "Successful\n",
      "63.txt\n",
      "Successful\n",
      "64.txt\n",
      "Successful\n",
      "65.txt\n",
      "Successful\n",
      "66.txt\n",
      "Successful\n",
      "67.txt\n",
      "Successful\n",
      "68.txt\n",
      "Successful\n",
      "69.txt\n",
      "Successful\n",
      "70.txt\n",
      "Successful\n",
      "71.txt\n",
      "Successful\n",
      "72.txt\n",
      "Successful\n",
      "73.txt\n",
      "Successful\n",
      "74.txt\n",
      "Successful\n",
      "75.txt\n",
      "Successful\n",
      "76.txt\n",
      "Successful\n",
      "77.txt\n",
      "Successful\n",
      "78.txt\n",
      "Successful\n",
      "79.txt\n",
      "Successful\n",
      "80.txt\n",
      "Successful\n",
      "81.txt\n",
      "Successful\n",
      "82.txt\n",
      "Successful\n",
      "83.txt\n",
      "Successful\n",
      "84.txt\n",
      "Successful\n",
      "85.txt\n",
      "Successful\n",
      "86.txt\n",
      "Successful\n",
      "87.txt\n",
      "Successful\n",
      "88.txt\n",
      "Successful\n",
      "89.txt\n",
      "Successful\n",
      "90.txt\n",
      "Successful\n",
      "91.txt\n",
      "Successful\n",
      "92.txt\n",
      "Successful\n",
      "93.txt\n",
      "Successful\n",
      "94.txt\n",
      "Successful\n",
      "95.txt\n",
      "Successful\n",
      "96.txt\n",
      "Successful\n",
      "97.txt\n",
      "Successful\n",
      "98.txt\n",
      "Successful\n",
      "99.txt\n",
      "Successful\n",
      "100.txt\n",
      "Successful\n",
      "101.txt\n",
      "Successful\n",
      "102.txt\n",
      "Successful\n",
      "103.txt\n",
      "Successful\n",
      "104.txt\n",
      "Successful\n",
      "105.txt\n",
      "Successful\n",
      "106.txt\n",
      "Successful\n",
      "107.txt\n",
      "Successful\n",
      "108.txt\n",
      "Successful\n",
      "109.txt\n",
      "Successful\n",
      "110.txt\n",
      "Successful\n",
      "111.txt\n",
      "Successful\n",
      "112.txt\n",
      "Successful\n",
      "113.txt\n",
      "Successful\n",
      "114.txt\n",
      "Successful\n",
      "115.txt\n",
      "Successful\n",
      "116.txt\n",
      "Successful\n",
      "117.txt\n",
      "Successful\n",
      "118.txt\n",
      "Successful\n",
      "119.txt\n",
      "Successful\n",
      "120.txt\n",
      "Successful\n",
      "121.txt\n",
      "Successful\n",
      "122.txt\n",
      "Successful\n",
      "123.txt\n",
      "Successful\n",
      "124.txt\n",
      "Successful\n",
      "125.txt\n",
      "Successful\n",
      "126.txt\n",
      "Successful\n",
      "127.txt\n",
      "Successful\n",
      "128.txt\n",
      "Successful\n",
      "129.txt\n",
      "Successful\n",
      "130.txt\n",
      "Successful\n",
      "131.txt\n",
      "Successful\n",
      "132.txt\n",
      "Successful\n",
      "133.txt\n",
      "Successful\n",
      "134.txt\n",
      "Successful\n",
      "135.txt\n",
      "Successful\n",
      "136.txt\n",
      "Successful\n",
      "137.txt\n",
      "Successful\n",
      "138.txt\n",
      "Successful\n",
      "139.txt\n",
      "Successful\n",
      "140.txt\n",
      "Successful\n",
      "141.txt\n",
      "Successful\n",
      "142.txt\n",
      "Successful\n",
      "143.txt\n",
      "Successful\n",
      "144.txt\n",
      "Successful\n",
      "145.txt\n",
      "Successful\n",
      "146.txt\n",
      "Successful\n",
      "147.txt\n",
      "Successful\n",
      "148.txt\n",
      "Successful\n",
      "149.txt\n",
      "Successful\n",
      "150.txt\n",
      "Successful\n",
      "151.txt\n",
      "Successful\n",
      "152.txt\n",
      "Successful\n",
      "153.txt\n",
      "Successful\n",
      "154.txt\n",
      "Successful\n",
      "155.txt\n",
      "Successful\n",
      "156.txt\n",
      "Successful\n",
      "157.txt\n",
      "Successful\n",
      "158.txt\n",
      "Successful\n",
      "159.txt\n",
      "Successful\n",
      "160.txt\n",
      "Successful\n",
      "161.txt\n",
      "Successful\n",
      "162.txt\n",
      "Successful\n",
      "163.txt\n",
      "Successful\n",
      "164.txt\n",
      "Successful\n",
      "165.txt\n",
      "Successful\n",
      "166.txt\n",
      "Successful\n",
      "167.txt\n",
      "Successful\n",
      "168.txt\n",
      "Successful\n",
      "169.txt\n",
      "Successful\n",
      "170.txt\n",
      "Successful\n",
      "171.txt\n",
      "Successful\n",
      "Wall time: 879 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pro = []\n",
    "\n",
    "\n",
    "for x in t_file:\n",
    "    article = open(x, encoding = 'mbcs').read().lower()\n",
    "    \n",
    "        \n",
    "    # Average Word Length\n",
    "    p = pronouns_count(article)\n",
    "    pro.append(p)\n",
    "    \n",
    "    print(x)\n",
    "    print('Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa81ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a20d3d",
   "metadata": {},
   "source": [
    "## Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45f7d4",
   "metadata": {},
   "source": [
    "We count the number of **Syllables** in each word of the text by counting the vowels present in each word. We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba145c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(text):\n",
    "    sk = RegexpTokenizer(\"(?:[aeiouAEIOU][r|w]|[aA|eE|iI|oO|uU|yY][aeiouyAEIOUY]|[aeiouyAEIOUY]r|[a-zA-Z]y|es|ed|ear|[aeiouAEIOU])\")\n",
    "    \n",
    "    d = sk.tokenize(text)\n",
    "    sc = len(d)\n",
    "    \n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b72d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count_per_word(text):\n",
    "    sk = RegexpTokenizer(\"(?:[aeiouAEIOU][r|w]|[aA|eE|iI|oO|uU|yY][aeiouyAEIOUY]|[aeiouyAEIOUY]r|[a-zA-Z]y|es|ed|ear|[aeiouAEIOU])\")\n",
    "    tk1 = RegexpTokenizer(\"[\\w']+\") # tokenize word\n",
    "    \n",
    "    d = sk.tokenize(text)\n",
    "    sc = len(d)\n",
    "    \n",
    "    r = tk1.tokenize(text)\n",
    "    wc = len(r)\n",
    "    \n",
    "    pw = sc/wc\n",
    "    \n",
    "    return pw    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f32a803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "Successful\n",
      "2.txt\n",
      "Successful\n",
      "3.txt\n",
      "Successful\n",
      "4.txt\n",
      "Successful\n",
      "5.txt\n",
      "Successful\n",
      "6.txt\n",
      "Successful\n",
      "7.txt\n",
      "Successful\n",
      "8.txt\n",
      "Successful\n",
      "9.txt\n",
      "Successful\n",
      "10.txt\n",
      "Successful\n",
      "11.txt\n",
      "Successful\n",
      "12.txt\n",
      "Successful\n",
      "13.txt\n",
      "Successful\n",
      "14.txt\n",
      "Successful\n",
      "15.txt\n",
      "Successful\n",
      "16.txt\n",
      "Successful\n",
      "17.txt\n",
      "Successful\n",
      "18.txt\n",
      "Successful\n",
      "19.txt\n",
      "Successful\n",
      "20.txt\n",
      "Successful\n",
      "21.txt\n",
      "Successful\n",
      "22.txt\n",
      "Successful\n",
      "23.txt\n",
      "Successful\n",
      "24.txt\n",
      "Successful\n",
      "25.txt\n",
      "Successful\n",
      "26.txt\n",
      "Successful\n",
      "27.txt\n",
      "Successful\n",
      "28.txt\n",
      "Successful\n",
      "29.txt\n",
      "Successful\n",
      "30.txt\n",
      "Successful\n",
      "31.txt\n",
      "Successful\n",
      "32.txt\n",
      "Successful\n",
      "33.txt\n",
      "Successful\n",
      "34.txt\n",
      "Successful\n",
      "35.txt\n",
      "Successful\n",
      "36.txt\n",
      "Successful\n",
      "37.txt\n",
      "Successful\n",
      "38.txt\n",
      "Successful\n",
      "39.txt\n",
      "Successful\n",
      "40.txt\n",
      "Successful\n",
      "41.txt\n",
      "Successful\n",
      "42.txt\n",
      "Successful\n",
      "43.txt\n",
      "Successful\n",
      "45.txt\n",
      "Successful\n",
      "46.txt\n",
      "Successful\n",
      "47.txt\n",
      "Successful\n",
      "48.txt\n",
      "Successful\n",
      "49.txt\n",
      "Successful\n",
      "50.txt\n",
      "Successful\n",
      "51.txt\n",
      "Successful\n",
      "52.txt\n",
      "Successful\n",
      "53.txt\n",
      "Successful\n",
      "54.txt\n",
      "Successful\n",
      "55.txt\n",
      "Successful\n",
      "56.txt\n",
      "Successful\n",
      "57.txt\n",
      "Successful\n",
      "58.txt\n",
      "Successful\n",
      "59.txt\n",
      "Successful\n",
      "60.txt\n",
      "Successful\n",
      "61.txt\n",
      "Successful\n",
      "62.txt\n",
      "Successful\n",
      "63.txt\n",
      "Successful\n",
      "64.txt\n",
      "Successful\n",
      "65.txt\n",
      "Successful\n",
      "66.txt\n",
      "Successful\n",
      "67.txt\n",
      "Successful\n",
      "68.txt\n",
      "Successful\n",
      "69.txt\n",
      "Successful\n",
      "70.txt\n",
      "Successful\n",
      "71.txt\n",
      "Successful\n",
      "72.txt\n",
      "Successful\n",
      "73.txt\n",
      "Successful\n",
      "74.txt\n",
      "Successful\n",
      "75.txt\n",
      "Successful\n",
      "76.txt\n",
      "Successful\n",
      "77.txt\n",
      "Successful\n",
      "78.txt\n",
      "Successful\n",
      "79.txt\n",
      "Successful\n",
      "80.txt\n",
      "Successful\n",
      "81.txt\n",
      "Successful\n",
      "82.txt\n",
      "Successful\n",
      "83.txt\n",
      "Successful\n",
      "84.txt\n",
      "Successful\n",
      "85.txt\n",
      "Successful\n",
      "86.txt\n",
      "Successful\n",
      "87.txt\n",
      "Successful\n",
      "88.txt\n",
      "Successful\n",
      "89.txt\n",
      "Successful\n",
      "90.txt\n",
      "Successful\n",
      "91.txt\n",
      "Successful\n",
      "92.txt\n",
      "Successful\n",
      "93.txt\n",
      "Successful\n",
      "94.txt\n",
      "Successful\n",
      "95.txt\n",
      "Successful\n",
      "96.txt\n",
      "Successful\n",
      "97.txt\n",
      "Successful\n",
      "98.txt\n",
      "Successful\n",
      "99.txt\n",
      "Successful\n",
      "100.txt\n",
      "Successful\n",
      "101.txt\n",
      "Successful\n",
      "102.txt\n",
      "Successful\n",
      "103.txt\n",
      "Successful\n",
      "104.txt\n",
      "Successful\n",
      "105.txt\n",
      "Successful\n",
      "106.txt\n",
      "Successful\n",
      "107.txt\n",
      "Successful\n",
      "108.txt\n",
      "Successful\n",
      "109.txt\n",
      "Successful\n",
      "110.txt\n",
      "Successful\n",
      "111.txt\n",
      "Successful\n",
      "112.txt\n",
      "Successful\n",
      "113.txt\n",
      "Successful\n",
      "114.txt\n",
      "Successful\n",
      "115.txt\n",
      "Successful\n",
      "116.txt\n",
      "Successful\n",
      "117.txt\n",
      "Successful\n",
      "118.txt\n",
      "Successful\n",
      "119.txt\n",
      "Successful\n",
      "120.txt\n",
      "Successful\n",
      "121.txt\n",
      "Successful\n",
      "122.txt\n",
      "Successful\n",
      "123.txt\n",
      "Successful\n",
      "124.txt\n",
      "Successful\n",
      "125.txt\n",
      "Successful\n",
      "126.txt\n",
      "Successful\n",
      "127.txt\n",
      "Successful\n",
      "128.txt\n",
      "Successful\n",
      "129.txt\n",
      "Successful\n",
      "130.txt\n",
      "Successful\n",
      "131.txt\n",
      "Successful\n",
      "132.txt\n",
      "Successful\n",
      "133.txt\n",
      "Successful\n",
      "134.txt\n",
      "Successful\n",
      "135.txt\n",
      "Successful\n",
      "136.txt\n",
      "Successful\n",
      "137.txt\n",
      "Successful\n",
      "138.txt\n",
      "Successful\n",
      "139.txt\n",
      "Successful\n",
      "140.txt\n",
      "Successful\n",
      "141.txt\n",
      "Successful\n",
      "142.txt\n",
      "Successful\n",
      "143.txt\n",
      "Successful\n",
      "144.txt\n",
      "Successful\n",
      "145.txt\n",
      "Successful\n",
      "146.txt\n",
      "Successful\n",
      "147.txt\n",
      "Successful\n",
      "148.txt\n",
      "Successful\n",
      "149.txt\n",
      "Successful\n",
      "150.txt\n",
      "Successful\n",
      "151.txt\n",
      "Successful\n",
      "152.txt\n",
      "Successful\n",
      "153.txt\n",
      "Successful\n",
      "154.txt\n",
      "Successful\n",
      "155.txt\n",
      "Successful\n",
      "156.txt\n",
      "Successful\n",
      "157.txt\n",
      "Successful\n",
      "158.txt\n",
      "Successful\n",
      "159.txt\n",
      "Successful\n",
      "160.txt\n",
      "Successful\n",
      "161.txt\n",
      "Successful\n",
      "162.txt\n",
      "Successful\n",
      "163.txt\n",
      "Successful\n",
      "164.txt\n",
      "Successful\n",
      "165.txt\n",
      "Successful\n",
      "166.txt\n",
      "Successful\n",
      "167.txt\n",
      "Successful\n",
      "168.txt\n",
      "Successful\n",
      "169.txt\n",
      "Successful\n",
      "170.txt\n",
      "Successful\n",
      "171.txt\n",
      "Successful\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "syl = []\n",
    "syl_w = []\n",
    "\n",
    "\n",
    "for x in t_file:\n",
    "    article = open(x, encoding = 'mbcs').read().lower()\n",
    "    \n",
    "        \n",
    "    # Syllable Count\n",
    "    h = syllable_count(article)\n",
    "    syl.append(h)\n",
    "    \n",
    "    \n",
    "    # Syllable Count Per Word\n",
    "    g = syllable_count_per_word(article)\n",
    "    syl_w.append(g)\n",
    "    \n",
    "    \n",
    "    print(x)\n",
    "    print('Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31efaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_excel('Output Data Structure.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3df34167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
       "       'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
       "       'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
       "       'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
       "       'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH',\n",
       "       'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
       "       'Unnamed: 19', 'Unnamed: 20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "381d8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save computed variable in output data structure\n",
    "\n",
    "output['POSITIVE SCORE'] = score_1\n",
    "output['NEGATIVE SCORE'] = score_2\n",
    "output['POLARITY SCORE'] = score_3\n",
    "output['SUBJECTIVITY SCORE'] = score_4\n",
    "\n",
    "output['AVG SENTENCE LENGTH'] = sent\n",
    "output['PERCENTAGE OF COMPLEX WORDS'] = percent\n",
    "output['FOG INDEX'] = fog_index\n",
    "\n",
    "output['AVG NUMBER OF WORDS PER SENTENCE'] = sent\n",
    "output['COMPLEX WORD COUNT'] = hard\n",
    "output['WORD COUNT'] = cl_w\n",
    "\n",
    "output['SYLLABLE PER WORD'] =  syl_w\n",
    "output['PERSONAL PRONOUNS'] = pro\n",
    "output['AVG WORD LENGTH'] = awl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f851c",
   "metadata": {},
   "source": [
    "<img src=\"Gunning fog.jpg\" width=\"200\" height=\"200\" align=\"center\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce1ab634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Computed Variable 'Reading Level By Grade'\n",
    "\n",
    "rl = []\n",
    "\n",
    "for num in fog_index:\n",
    "    if 6 <= num <= 7:\n",
    "        rl.append('6th Grade')\n",
    "    elif 7 <= num <= 8:\n",
    "        rl.append('7th Grade')\n",
    "    elif 8 <= num <= 9:\n",
    "        rl.append('8th Grade')\n",
    "    elif 9 <= num <= 10:\n",
    "        rl.append('High School freshman')\n",
    "    elif 10 <= num <= 11:\n",
    "        rl.append('High School sophomore')\n",
    "    elif 11 <= num <= 12:\n",
    "        rl.append('High School junior')\n",
    "    elif 12 <= num <= 13:\n",
    "        rl.append('High School senior')\n",
    "    elif 13 <= num <= 14:\n",
    "        rl.append('College freshman')\n",
    "    elif 14 <= num <= 15:\n",
    "        rl.append('College sophomore')\n",
    "    elif 15 <= num <= 16:\n",
    "        rl.append('College junior')\n",
    "    elif 16 <= num <= 17:\n",
    "        rl.append('College Senior')\n",
    "    elif num > 20:\n",
    "        rl.append('Hard to read')\n",
    "    elif num < 6:\n",
    "        rl.append('Easy to read')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8dd0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns 'TOTAL SYLLABLE COUNT' & 'READING LEVEL BY GRADE'\n",
    "\n",
    "output['TOTAL SYLLABLE COUNT'] = syl\n",
    "output['READING LEVEL BY GRADE'] = rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "663b7434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
       "       'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
       "       'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
       "       'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
       "       'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH',\n",
       "       'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
       "       'Unnamed: 19', 'Unnamed: 20', 'TOTAL SYLLABLE COUNT',\n",
       "       'READING LEVEL BY GRADE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e0cbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the columns in pandas df\n",
    "\n",
    "output = output[['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
    "       'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
    "       'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'READING LEVEL BY GRADE',\n",
    "       'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "       'SYLLABLE PER WORD', 'TOTAL SYLLABLE COUNT','PERSONAL PRONOUNS', 'AVG WORD LENGTH',\n",
    "        'Unnamed: 15','Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
    "       'Unnamed: 19', 'Unnamed: 20']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b84b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>READING LEVEL BY GRADE</th>\n",
       "      <th>...</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>TOTAL SYLLABLE COUNT</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>29.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>11.69</td>\n",
       "      <td>High School junior</td>\n",
       "      <td>...</td>\n",
       "      <td>1.761589</td>\n",
       "      <td>1330</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>22.21</td>\n",
       "      <td>0.18</td>\n",
       "      <td>8.96</td>\n",
       "      <td>8th Grade</td>\n",
       "      <td>...</td>\n",
       "      <td>1.881720</td>\n",
       "      <td>1225</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.09</td>\n",
       "      <td>23.57</td>\n",
       "      <td>0.19</td>\n",
       "      <td>9.50</td>\n",
       "      <td>High School freshman</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836702</td>\n",
       "      <td>3453</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>34.77</td>\n",
       "      <td>0.18</td>\n",
       "      <td>13.98</td>\n",
       "      <td>College freshman</td>\n",
       "      <td>...</td>\n",
       "      <td>1.893013</td>\n",
       "      <td>867</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.10</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.87</td>\n",
       "      <td>8th Grade</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791503</td>\n",
       "      <td>2277</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0       1  https://insights.blackcoffer.com/how-is-login-...              13   \n",
       "1       2  https://insights.blackcoffer.com/how-does-ai-h...              22   \n",
       "2       3  https://insights.blackcoffer.com/ai-and-its-im...              70   \n",
       "3       4  https://insights.blackcoffer.com/how-do-deep-l...              13   \n",
       "4       5  https://insights.blackcoffer.com/how-artificia...              47   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0               9            0.18                0.06                29.08   \n",
       "1               3            0.76                0.08                22.21   \n",
       "2              18            0.59                0.09                23.57   \n",
       "3               0            1.00                0.06                34.77   \n",
       "4              12            0.59                0.10                22.00   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX READING LEVEL BY GRADE  ...  \\\n",
       "0                         0.15      11.69     High School junior  ...   \n",
       "1                         0.18       8.96              8th Grade  ...   \n",
       "2                         0.19       9.50   High School freshman  ...   \n",
       "3                         0.18      13.98       College freshman  ...   \n",
       "4                         0.17       8.87              8th Grade  ...   \n",
       "\n",
       "   SYLLABLE PER WORD  TOTAL SYLLABLE COUNT  PERSONAL PRONOUNS  \\\n",
       "0           1.761589                  1330                 13   \n",
       "1           1.881720                  1225                 21   \n",
       "2           1.836702                  3453                 45   \n",
       "3           1.893013                   867                  7   \n",
       "4           1.791503                  2277                 40   \n",
       "\n",
       "   AVG WORD LENGTH  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
       "0                5          NaN          NaN          NaN          NaN   \n",
       "1                5          NaN          NaN          NaN          NaN   \n",
       "2                5          NaN          NaN          NaN          NaN   \n",
       "3                5          NaN          NaN          NaN          NaN   \n",
       "4                5          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 19  Unnamed: 20  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc2a8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnamed columns\n",
    "output.drop(['Unnamed: 15','Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
    "       'Unnamed: 19', 'Unnamed: 20'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ab69cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "# determining the name of the file\n",
    "file_name = 'Output Data Structure.xlsx'\n",
    "  \n",
    "# saving the excel\n",
    "output.to_excel(file_name)\n",
    "print('DataFrame is written to Excel File successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
